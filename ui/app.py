# import streamlit as st
# import json
# import streamlit.components.v1 as components
# from utils import load_thread_data, get_thread_by_id

# st.set_page_config(page_title="ThreadNavigatorAI 2.0", layout="wide")
# st.title("🧵 ThreadNavigatorAI 2.0")

# # 🧬 How it Works
# with st.expander("🧬 How This Works (click to expand)", expanded=False):
#     st.markdown("""
#     **ThreadNavigatorAI 2.0** is a modular, multi-agent pipeline that mimics how a human analyst might navigate noisy Reddit threads:

#     1. 🔍 **Summarizer Agent** condenses user-generated content using semantic transformers.
#     2. 🧪 **Fact Checker Agent** flags or affirms claims using external tool-augmented retrieval.
#     3. 🧠 **Evaluator Agent** applies LLM-based rubrics (Relevance, Factuality, Coherence).

#     The system supports both real API calls and mock simulations to benchmark scalability under OpenRouter’s free-tier.
#     """)

# # 🧭 Onboarding (one-time info message)
# if "show_guide" not in st.session_state:
#     st.session_state.show_guide = True
# if st.session_state.show_guide:
#     st.info("👋 Welcome! Use the selector below to explore 100 Reddit threads processed by AI agents. You can toggle latency, evaluation, and download options in the sidebar.")
#     if st.button("Got it! Hide this message"):
#         st.session_state.show_guide = False

# # Sidebar: About + Toggle Controls
# st.sidebar.markdown("## 📚 About")
# st.sidebar.markdown("ThreadNavigatorAI analyzes Reddit threads using multi-agent LLMs.")
# with st.sidebar.expander("⚙️ Toggle Display Options"):
#     show_latency = st.checkbox("Show Latency", value=True)
#     show_eval = st.checkbox("Show Evaluation", value=True)
#     show_download = st.checkbox("Enable Download", value=True)
# st.sidebar.markdown("---")
# st.sidebar.markdown("A multi-agent Reddit thread analyzer built by Rajesh 💼")

# # Load data
# data = load_thread_data()
# thread_ids = [t["thread_id"] for t in data]

# # Thread selector
# selected_id = st.selectbox("🎯 Select a Reddit Thread", thread_ids)
# thread = get_thread_by_id(data, selected_id)

# # Reset copy flag when thread changes
# if "last_selected_id" not in st.session_state:
#     st.session_state.last_selected_id = selected_id
# if selected_id != st.session_state.last_selected_id:
#     st.session_state.summary_copied = False
#     st.session_state.last_selected_id = selected_id

# if thread:
#     st.subheader("📌 Title:")
#     st.markdown(f"**{thread['title']}**")

#     # Summary type and source
#     is_mock = thread.get("is_mock", False)
#     summary_type = "🤖 Simulated Summary" if is_mock else "🔁 Real Summary"
#     summary_color = "#e0e0e0" if is_mock else "#d4edda"
#     source_url = thread.get("source_url", "")
#     source_html = f'<b>📎 Source:</b> <a href="{source_url}" target="_blank">Reddit Thread</a>' if source_url else ""

#     st.markdown(f"""
#         <div style='background-color:{summary_color};padding:10px;border-radius:10px;margin-bottom:10px'>
#             <b>Summary Type:</b> {summary_type}<br>
#             {source_html}
#         </div>
#     """, unsafe_allow_html=True)

#     with st.expander("💬 View Original Posts", expanded=False):
#         for post in thread["posts"]:
#             st.markdown(f"- {post}")


#     # Define tab labels dynamically
#     tab_labels = ["🧠 Summary", "🔎 Fact Checks"]
#     if show_latency:
#         tab_labels.append("⚡ Latency")
#     if show_eval:
#         tab_labels.append("📊 Evaluation")

#     tabs = st.tabs(tab_labels)
#     tab_index = 0

#     # 🧠 Summary Tab
#     with tabs[tab_index]:
#         st.markdown("### Summary")
#         st.markdown(
#             f"""
#             <div style='background-color:#f8f9fa; padding:12px; border-radius:8px;
#                         font-family:monospace;  word-wrap:break-word;
#                         border:1px solid #ddd; margin-bottom:10px'>
#                 {thread["summary"]}
#             </div>
#             """, unsafe_allow_html=True)

#         # Model attribution
#         model_summary = thread.get("models_used", {}).get("summarizer", "Unknown")
#         st.markdown(f"<span style='color:gray;font-size:small'>🧠 Generated by: `{model_summary}`</span>", unsafe_allow_html=True)

#         if show_download:
#             json_str = json.dumps(thread, indent=2)
#             st.download_button(
#                 "⬇️ Download JSON Result",
#                 data=json_str,
#                 file_name=f"{thread['thread_id']}.json",
#                 mime="application/json"
#             )

#     tab_index += 1

#     # 🔎 Fact Checks Tab
#     with tabs[tab_index]:
#         st.markdown("### Fact Checks")
#         model_fc = thread.get("models_used", {}).get("factchecker", "Unknown")
#         st.markdown(f"<span style='color:gray;font-size:small'>🔎 Checked by: `{model_fc}`</span>", unsafe_allow_html=True)
#         for f in thread["fact_check"]:
#             judgment = f["judgment"]
#             emoji = "🟢" if "Correct" in judgment else "🔴" if "Incorrect" in judgment else "⚪"
#             st.markdown(f"- **Claim:** {f['claim']}  \n  **Judgment:** {emoji} {judgment}")

#     tab_index += 1

#     # ⚡ Latency Tab
#     if show_latency:
#         with tabs[tab_index]:
#             st.markdown("### Agent Latency")
#             latency = thread.get("latency", {})
#             models = thread.get("models_used", {})
#             if latency:
#                 for k, v in latency.items():
#                     model_name = models.get(k.lower(), "Unknown")
#                     st.markdown(f"- **{k.capitalize()}**: {v} sec  \n  <span style='color:gray;font-size:small'>Model: `{model_name}`</span>", unsafe_allow_html=True)
#             else:
#                 st.info("Latency not recorded for this thread.")
#         tab_index += 1

#     # 📊 Evaluation Tab
#     if show_eval:
#         with tabs[tab_index]:
#             st.markdown("### Evaluation")
#             eval_ = thread["evaluation"]
#             if isinstance(eval_, str):
#                 eval_ = json.loads(eval_)
#             if isinstance(eval_, dict):
#                 for k, v in eval_.items():
#                     score = v["score"]
#                     reason = v["reason"]
#                     emoji = "🟢" if score >= 4 else "🟡" if score == 3 else "🔴"
#                     st.markdown(f"- **{k.capitalize()}**: {emoji} {score} — {reason}")
#             else:
#                 st.warning(f"Evaluation skipped: {eval_}")

#     st.caption("✅ Powered by OpenRouter LLMs and modular multi-agent stack.")


# import streamlit as st
# import json
# import streamlit.components.v1 as components
# from utils import load_thread_data, get_thread_by_id

# st.set_page_config(page_title="ThreadNavigatorAI 2.0", layout="wide")
# st.title("🧵 ThreadNavigatorAI 2.0")

# # 🧬 How it Works
# with st.expander("🧬 How This Works (click to expand)", expanded=False):
#     st.markdown("""
#     **ThreadNavigatorAI 2.0** is a modular, multi-agent pipeline that mimics how a human analyst might navigate noisy Reddit threads:

#     1. 🔍 **Summarizer Agent** condenses user-generated content using semantic transformers.
#     2. 🧪 **Fact Checker Agent** flags or affirms claims using external tool-augmented retrieval.
#     3. 🧠 **Evaluator Agent** applies LLM-based rubrics (Relevance, Factuality, Coherence).

#     The system supports both real API calls and mock simulations to benchmark scalability under OpenRouter’s free-tier.

#     ✨ This project builds on lessons from [ThreadNavigatorAI 1.0](https://github.com/rajesh1804/ThreadNavigatorAI), which used a simpler single-agent design.
#     """)

# # 🧭 Onboarding (one-time info message)
# if "show_guide" not in st.session_state:
#     st.session_state.show_guide = True
# if st.session_state.show_guide:
#     st.info("👋 Welcome! Use the selector below to explore 100 Reddit threads processed by AI agents. You can toggle latency, evaluation, and download options in the sidebar.")
#     if st.button("Got it! Hide this message"):
#         st.session_state.show_guide = False

# # Sidebar: About + Toggle Controls
# st.sidebar.markdown("## 📚 About")
# st.sidebar.markdown("ThreadNavigatorAI analyzes Reddit threads using multi-agent LLMs.")
# st.sidebar.markdown("\n**Key Features:**\n- Multi-agent architecture\n- LLM-as-a-Judge evaluation\n- Real & Simulated hybrid inference")

# st.sidebar.markdown("\n📈 **LLM-as-a-Judge enabled via OpenRouter**")

# with st.sidebar.expander("⚙️ Toggle Display Options"):
#     show_latency = st.checkbox("Show Latency", value=True)
#     show_eval = st.checkbox("Show Evaluation", value=True)
#     show_download = st.checkbox("Enable Download", value=True)

# st.sidebar.markdown("---")
# st.sidebar.markdown("A multi-agent Reddit thread analyzer built by Rajesh 💼")

# # Visual Flow Diagram
# with st.expander("📊 Agent Pipeline Diagram"):
#     st.image("assets/threadnavigator_flow.png", caption="ThreadNavigatorAI Multi-Agent Flow")

# # Load data
# data = load_thread_data()
# thread_ids = [t["thread_id"] for t in data]

# # Thread selector
# selected_id = st.selectbox("🎯 Select a Reddit Thread", thread_ids)
# thread = get_thread_by_id(data, selected_id)

# # Reset copy flag when thread changes
# if "last_selected_id" not in st.session_state:
#     st.session_state.last_selected_id = selected_id
# if selected_id != st.session_state.last_selected_id:
#     st.session_state.summary_copied = False
#     st.session_state.last_selected_id = selected_id

# if thread:
#     st.subheader(f"📌 Title: **{thread['title']}**")
#     # st.markdown(f"**{thread['title']}**")

#     # Summary type and source
#     is_mock = thread.get("is_mock", False)
#     summary_type = "🤖 Simulated Summary" if is_mock else "🔁 Real Summary"
#     summary_color = "#e0e0e0" if is_mock else "#d4edda"
#     source_url = thread.get("source_url", "")
#     source_html = f'<b>📌 Source:</b> <a href="{source_url}" target="_blank">Reddit Thread</a>' if source_url else ""

#     st.markdown(f"""
#         <div style='background-color:{summary_color};padding:10px;border-radius:10px;margin-bottom:10px'>
#             <b>Summary Type:</b> {summary_type}<br>
#             {source_html}
#         </div>
#     """, unsafe_allow_html=True)

#     with st.expander("💬 View Original Posts", expanded=False):
#         for post in thread["posts"]:
#             st.markdown(f"- {post}")

#     # Define tab labels dynamically
#     tab_labels = ["🧠 Summary", "🔎 Fact Checks"]
#     if show_latency:
#         tab_labels.append("⚡ Latency")
#     if show_eval:
#         tab_labels.append("📊 Evaluation")

#     tabs = st.tabs(tab_labels)
#     tab_index = 0

#     # 🧠 Summary Tab
#     with tabs[tab_index]:
#         st.markdown("### 📝 Key Insights")
#         st.markdown(
#             f"""
#             <div style='background-color:#f8f9fa; padding:12px; border-radius:8px;
#                         font-family:monospace;  word-wrap:break-word;
#                         border:1px solid #ddd; margin-bottom:10px'>
#                 {thread["summary"]}
#             </div>
#             """, unsafe_allow_html=True)

#         model_summary = thread.get("models_used", {}).get("summarizer", "Unknown")
#         st.markdown(f"<span style='color:gray;font-size:small'>🧠 Generated by: `{model_summary}`</span>", unsafe_allow_html=True)

#         if show_download:
#             json_str = json.dumps(thread, indent=2)
#             st.download_button(
#                 "⬇️ Download JSON Result",
#                 data=json_str,
#                 file_name=f"{thread['thread_id']}.json",
#                 mime="application/json"
#             )

#     tab_index += 1

#     # 🔎 Fact Checks Tab
#     with tabs[tab_index]:
#         st.markdown("### Fact Checks")
#         model_fc = thread.get("models_used", {}).get("factchecker", "Unknown")
#         st.markdown(f"<span style='color:gray;font-size:small'>🔎 Checked by: `{model_fc}`</span>", unsafe_allow_html=True)
#         for f in thread["fact_check"]:
#             judgment = f["judgment"]
#             emoji = "🟢" if "Correct" in judgment else "🔴" if "Incorrect" in judgment else "⚪"
#             st.markdown(f"- **Claim:** {f['claim']}  \n  **Judgment:** {emoji} {judgment}")

#     tab_index += 1

#     if show_latency:
#         with tabs[tab_index]:
#             st.markdown("### Agent Latency")
#             latency = thread.get("latency", {})
#             models = thread.get("models_used", {})
#             if latency:
#                 for k, v in latency.items():
#                     model_name = models.get(k.lower(), "Unknown")
#                     st.markdown(f"- **{k.capitalize()}**: {v} sec  \n  <span style='color:gray;font-size:small'>Model: `{model_name}`</span>", unsafe_allow_html=True)
#             else:
#                 st.info("Latency not recorded for this thread.")
#         tab_index += 1

#     if show_eval:
#         with tabs[tab_index]:
#             st.markdown("### Evaluation")
#             eval_ = thread["evaluation"]
#             if isinstance(eval_, str):
#                 eval_ = json.loads(eval_)
#             if isinstance(eval_, dict):
#                 for k, v in eval_.items():
#                     score = v["score"]
#                     reason = v["reason"]
#                     emoji = "🟢" if score >= 4 else "🟡" if score == 3 else "🔴"
#                     st.markdown(f"- **{k.capitalize()}**: {emoji} {score} — {reason}")
#             else:
#                 st.warning(f"Evaluation skipped: {eval_}")

#     st.caption("✅ Powered by OpenRouter LLMs and modular multi-agent stack.")


import streamlit as st
import json
import streamlit.components.v1 as components
from utils import load_thread_data, get_thread_by_id

st.set_page_config(page_title="ThreadNavigatorAI 2.0", layout="wide")
st.title("🧵 ThreadNavigatorAI 2.0")

# ================================
# 👋 Onboarding Info
# ================================
st.info("👋 Welcome! Use the selector below to explore 100 Reddit threads processed by AI agents. Toggle options in the sidebar.")
    

# ===================================
# 📚 Sidebar - Info + Display toggles
# ===================================
st.sidebar.markdown("## 📚 About")
st.sidebar.markdown("ThreadNavigatorAI analyzes Reddit threads using multi-agent LLMs.")
st.sidebar.markdown("""
**Key Features:**
- Multi-agent architecture
- LLM-as-a-Judge evaluation
- Real & Simulated hybrid inference
""")
st.sidebar.markdown("📈 Powered by OpenRouter APIs")

with st.sidebar.expander("⚙️ Toggle Display Options"):
    show_latency = st.checkbox("Show Latency", value=True)
    show_eval = st.checkbox("Show Evaluation", value=True)
    show_download = st.checkbox("Enable Download", value=True)

st.sidebar.markdown("---")
st.sidebar.write("👨‍💻 A multi-agent Reddit thread analyzer built by Rajesh Marudhachalam")
st.sidebar.write("🐙 [GitHub](https://github.com/rajesh1804) | 💼 [LinkedIn](https://linkedin.com/in/rajesh1804)")


# ================================================
# 🧬 Visual Storytelling (replaces expander layout)
# ================================================
with st.expander("## 🧭 How ThreadNavigatorAI Works ?", expanded=True):

    col1, col2 = st.columns([1.3, 1])

    with col1:
        st.markdown("""
    **ThreadNavigatorAI 2.0** mimics how a senior research analyst might make sense of chaotic online discussions — but with LLM agents:

    - 🔍 **Summarizer Agent** distills Reddit noise into coherent summaries.
    - 🧪 **Fact Checker Agent** verifies claims using tool-augmented LLMs.
    - 🧠 **Evaluator Agent** grades outputs on relevance, factuality, and coherence.

    The pipeline supports **real + simulated runs** to stay within free-tier OpenRouter limits.

    ✨ Originally built as an upgrade to [ThreadNavigatorAI 1.0](https://github.com/rajesh1804/ThreadNavigatorAI) — now with modularity, model tracking, and 100-thread benchmarking.
    """)

    with col2:
        st.image("https://github.com/rajesh1804/threadnavigatorai2.0/raw/main/assets/threadnavigator_flow.png", caption="🔁 Modular Multi-Agent Flow", use_column_width=True)

    st.markdown("<div style='text-align:center; color:gray; font-size:small;'>🧠 Built for clarity, modularity, and agentic transparency.</div>", unsafe_allow_html=True)

# =====================
# 📥 Load thread data
# =====================
data = load_thread_data()
thread_ids = [t["thread_id"] for t in data]

# Thread selector
selected_id = st.selectbox("🎯 Select a Reddit Thread", thread_ids,)
thread = get_thread_by_id(data, selected_id)

# Reset summary copy flag if thread changes
if "last_selected_id" not in st.session_state:
    st.session_state.last_selected_id = selected_id
if selected_id != st.session_state.last_selected_id:
    st.session_state.summary_copied = False
    st.session_state.last_selected_id = selected_id

# ====================================
# 🔍 Main thread analysis display
# ====================================
if thread:
    st.subheader(f"📌 Title: **{thread['title']}**")

    # Summary type + Reddit source link
    is_mock = thread.get("is_mock", False)
    summary_type = "🤖 Simulated Summary" if is_mock else "🔁 Real Summary"
    summary_color = "#e0e0e0" if is_mock else "#d4edda"
    source_url = thread.get("source_url", "")
    source_html = f'<b>📌 Source:</b> <a href="{source_url}" target="_blank">Reddit Thread</a>' if source_url else ""

    st.markdown(f"""
        <div style='background-color:{summary_color};padding:10px;border-radius:10px;margin-bottom:10px'>
            <b>Summary Type:</b> {summary_type}<br>
            {source_html}
        </div>
    """, unsafe_allow_html=True)

    with st.expander("💬 View Original Posts", expanded=False):
        for post in thread["posts"]:
            st.markdown(f"- {post}")

    # Dynamic tab labels
    tab_labels = ["🧠 Summary", "🔎 Fact Checks"]
    if show_latency:
        tab_labels.append("⚡ Latency")
    if show_eval:
        tab_labels.append("📊 Evaluation")

    tabs = st.tabs(tab_labels)
    tab_index = 0

    # 🧠 Summary Tab
    with tabs[tab_index]:
        st.markdown("### 📝 Key Insights")
        st.code(thread["summary"], language="markdown")

        model_summary = thread.get("models_used", {}).get("summarizer", "Unknown")
        st.markdown(f"<span style='color:gray;font-size:small'>🧠 Generated by: `{model_summary}`</span>", unsafe_allow_html=True)

        if show_download:
            json_str = json.dumps(thread, indent=2)
            st.download_button(
                "⬇️ Download JSON Result",
                data=json_str,
                file_name=f"{thread['thread_id']}.json",
                mime="application/json"
            )

    tab_index += 1

    # 🔎 Fact Checks Tab
    with tabs[tab_index]:
        st.markdown("### Fact Checks")
        model_fc = thread.get("models_used", {}).get("factchecker", "Unknown")
        st.markdown(f"<span style='color:gray;font-size:small'>🔎 Checked by: `{model_fc}`</span>", unsafe_allow_html=True)
        for f in thread["fact_check"]:
            judgment = f["judgment"]
            emoji = "🟢" if "Correct" in judgment else "🔴" if "Incorrect" in judgment else "⚪"
            st.markdown(f"- **Claim:** {f['claim']}  \n  **Judgment:** {emoji} {judgment}")

    tab_index += 1

    # ⚡ Latency Tab
    if show_latency:
        with tabs[tab_index]:
            st.markdown("### Agent Latency")
            latency = thread.get("latency", {})
            models = thread.get("models_used", {})
            if latency:
                for k, v in latency.items():
                    model_name = models.get(k.lower(), "Unknown")
                    st.markdown(f"- **{k.capitalize()}**: {v} sec  \n  <span style='color:gray;font-size:small'>Model: `{model_name}`</span>", unsafe_allow_html=True)
            else:
                st.info("Latency not recorded for this thread.")
        tab_index += 1

    # 📊 Evaluation Tab
    if show_eval:
        with tabs[tab_index]:
            st.markdown("### Evaluation")
            eval_ = thread["evaluation"]

            model_summary = thread.get("models_used", {}).get("evaluator", "Unknown")
            st.markdown(f"<span style='color:gray;font-size:small'>📊 Evaluated by: `{model_summary}`</span>", unsafe_allow_html=True)

            if isinstance(eval_, str):
                eval_ = json.loads(eval_)
            if isinstance(eval_, dict):
                for k, v in eval_.items():
                    score = v["score"]
                    reason = v["reason"]
                    emoji = "🟢" if score >= 4 else "🟡" if score == 3 else "🔴"
                    st.markdown(f"- **{k.capitalize()}**: {emoji} {score} — {reason}")
            else:
                st.warning(f"Evaluation skipped: {eval_}")

    st.markdown("---")
    st.caption("✅ Powered by OpenRouter LLMs and modular multi-agent stack.")
